{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data Science 101 - Lead Scoring Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Problem\n",
    "\n",
    "Today we are going to look at a very common data science problem found in e-commerce and web based software or services (like Xero!). **Lead scoring!**\n",
    "\n",
    "### The Sales Process\n",
    "\n",
    "An education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses.\n",
    "\n",
    "1. Individuals land on the website, they might browse the courses, watch some videos and if they are interested they will fill up a form for the course. \n",
    "\n",
    "1. Once individuals fill out a form, they have now become a potential customer or **lead**\n",
    "\n",
    "1. Employees from the sales team will contact leads by emailing or calling them with the goal of getting the lead to sign up for the course - called a **conversion** \n",
    "\n",
    "### Situation\n",
    "\n",
    "- Currently only 38% of leads contacted go on to become a paying customer. \n",
    "- The CEO wants to grow the customer base by 20% over the next year \n",
    "\n",
    "### Complication \n",
    "\n",
    "- The head of the sales & advertising department has budget to increase advertising by 20% generate more leads, but they would not have enough resource to still call every lead that signs up\n",
    "\n",
    "### Question\n",
    "\n",
    "- The department head knows that a conversion rate of 38% means a lot of time and money is wasted on customers who never intent to sign up. \n",
    "- They have asked you if there is a way to call only the 'hottest' leads and get a better return on the amount of sales calls they make?\n",
    "\n",
    "### Answer \n",
    "\n",
    "- You tell the department head it is possible to use historical data from previous leads who have and have not become customers to build a model to score how likely a lead its to convert!\n",
    "\n",
    "Your idea for a lead scoring gets approved - now you need to look at the data you and decide what model you are going to build!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tools\n",
    "\n",
    "Today we are going to be using a few different tools in our lead scoring scenario:\n",
    "\n",
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic python commands \n",
    "\n",
    "# create an array\n",
    "x = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`min`, `max` and `print` are what we call **functions**. These are preprogrammed commands to do common calculations on manipulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook in Google Colab\n",
    "\n",
    "Jupyter notebook contains **cells** to run each bit of code at a time \n",
    "\n",
    "You can run a cell by using `ctrl` + `enter` \n",
    "\n",
    "Or because we are hosting the notebook in Google Colab you can click the `play` button at the top of the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add a new text or code cell using the buttons at the top of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages\n",
    "\n",
    "To do data science we need to add a bit more functionality than is available in the base python code. \n",
    "\n",
    "We do this by importing packages that have extra functions for data analysis, statistics and machine learning.\n",
    "\n",
    "The data scientists tool kit generally includes the following packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package for multi-dimensional arrays and matrices\n",
    "import numpy as np\n",
    "\n",
    "# package for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# packages for creating plots and graphs \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# visulaisation\n",
    "from matplotlib.pyplot import xticks\n",
    "%matplotlib inline\n",
    "\n",
    "# ignoring any warnings for this tutorial \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `import` function to load the extra functions into our python session.\n",
    "\n",
    "The `as` just shortens the path name of the function so we can call `pd.function_name()` instead of `pandas.function_name()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Load Data\n",
    "\n",
    "We use functions from the `pandas` package to load in our data from a csv. Then it's important to check that we have infact loaded the data correctly! \n",
    "\n",
    "We can use functions to look at the number of rows and columns and because it is generally too big to look at once we can look at the first and last rows of the data. \n",
    "\n",
    "It's also very useful to look at the type of data in each column and check for any duplicates or missing/Null values! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data into a pandas dataframe\n",
    "leads_df = pd.read_csv('https://raw.githubusercontent.com/hjamau/ds-leadscore-tutorial/master/Leads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class of the object\n",
    "type(leads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows and columns \n",
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 rows of the dataframe head()\n",
    "leads_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 5 rows of the dataframe - tail()\n",
    "leads_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe \n",
    "leads_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "leads_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting columns\n",
    "leads_df.Specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this also selects a column\n",
    "leads_df['Specialization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also subset a dataframe to specific columns \n",
    "leads_df[['Specialization', 'Converted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do multiple functions in one command\n",
    "# letâ€™s use the converted column, sum and shape functions to check existing conversion rate in data set\n",
    "sum(leads_df.Converted)/leads_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the sum and dumplicated functions to do a very important step!\n",
    "# checking duplicates!!\n",
    "sum(leads_df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at null/missing values \n",
    "leads_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Data Cleaning\n",
    "\n",
    "In the real world we often have imperfect or missing data that we need to 'clean' to get ready for data analysis. \n",
    "\n",
    "Using what we learnt above about the data, we will now apply some changes to the dataframe to fill in any gaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are \"select\" values in columns, that doesn't make any sense for occupation\n",
    "# This is because customer did not select any option from the list, hence it shows select.\n",
    "\n",
    "# Change 'Select' values to NaN.\n",
    "leads_df = leads_df.replace('Select', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the specialization column\n",
    "leads_df['Specialization'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It maybe the case that lead has not entered any specialization if their option is not availabe on the list\n",
    "# We can make a category \"Others\" for missing values. \n",
    "leads_df['Specialization'] = leads_df['Specialization'].replace(np.nan, 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Data Exploration\n",
    "\n",
    "Each row in our data is a single observation made up of a values in each column. \n",
    "\n",
    "Now we have cleaned the data we can start exploring each of the columns we have as **variables** in the dataset:\n",
    "\n",
    "- `Prospect ID` is the identifier variable for the data across each row\n",
    "\n",
    "- `converted`  is our **target** variable (also known as the response variable) i.e. the variable that we are interested in predicting. \n",
    "\n",
    "    - It is binary and the event either happens or it doesn't i.e. 0 or 1\n",
    "\n",
    "- We have a mix of 7 categorical and continuous variables we can as **predictor** variables (also called explanatory variable, feature, input variable or independent variable)\n",
    "\n",
    "We can explore the data to see if there are any correlations between the target and predictor variables.\n",
    "\n",
    "First for our categorical variables let's look at side by side bar plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead Origin\n",
    "fig, axs = plt.subplots(figsize = (15,7.5))\n",
    "sns.countplot(x = \"LeadOrigin\", hue = \"Converted\", data = leads_df)\n",
    "xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead source\n",
    "fig, axs = plt.subplots(figsize = (15,7.5))\n",
    "sns.countplot(x = \"LeadSource\", hue = \"Converted\", data = leads_df)\n",
    "xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialization\n",
    "fig, axs = plt.subplots(figsize = (15,7.5))\n",
    "sns.countplot(x = \"Specialization\", hue = \"Converted\", data = leads_df)\n",
    "xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupation\n",
    "fig, axs = plt.subplots(figsize = (15,7.5))\n",
    "sns.countplot(x = \"Occupation\", hue = \"Converted\", data = leads_df)\n",
    "xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our continuous variables we can look at box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Visits\n",
    "sns.boxplot(y = 'TotalVisits', x = 'Converted', data = leads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Time Spent on Website\n",
    "sns.boxplot(y = 'TotalTime', x = 'Converted', data = leads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Views Per Visit\n",
    "sns.boxplot(y = 'PageViews', x = 'Converted', data = leads_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What comments can you make about the different variables and their conversion rates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Model Building \n",
    "\n",
    "Now we have a reasonably good idea about what we want to predict and the relationships in each variable we can start to build a predictive model for our lead score. \n",
    "\n",
    "As we said above we have a binary target that we want to predict and a mix of 7 categorical and continuous variables we can use as predictor variables \n",
    "\n",
    "Because our target is binary (0 or 1)  - this is a **classification** problem, meaning that we want to predict whether a lead will convert or not. \n",
    "\n",
    "So we need to pick a model for classification. The first choice for many binary classification problems is a **logistic regression** model because of its simplicity and interpretability. \n",
    "\n",
    "There are other options like **random forests** or **neural networks** that can provide better accuracy, but depending on the data logistic regression can perform very well! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-testing split\n",
    "\n",
    "The next part of building a predictive model is to split the data into a **training** set and **testing** set. \n",
    "This lets us withhold data from the model when training so that we can test it's performance on data it has not seen before - just like it will be doing for our lead scoring in real life. \n",
    "\n",
    "- Test 80% \n",
    "- Train 20% \n",
    "\n",
    "We also need to transform the data to get it ready for modelling \n",
    "- Remove the ID label (not useful as a predictor)\n",
    "- Split out the target column\n",
    "- For categorical variables with multiple levels, create dummy features (one-hot encoded)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package for training models \n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector to store conversion results\n",
    "y = leads_df['Converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking catagorical variables and creating dummy variables\n",
    "# here we have subsetted the dataframe to only the catagorical columns \n",
    "dummy1 = pd.get_dummies(leads_df[['LeadOrigin', 'LeadSource', 'Specialization', 'Occupation']], drop_first=True)\n",
    "dummy1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the results of the dummy variables and remaining continous variables \n",
    "# in a dataframe with all the predictors \n",
    "X = pd.concat([leads_df[['TotalVisits', 'TotalTime', 'PageViews']], dummy1], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to 'fit' our logistic regresion model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model \n",
    "lm = linear_model.LogisticRegression()\n",
    "model = lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy as that! Two lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Model Evaluation\n",
    "\n",
    "Next is the important bit - how good is our model at predicting conversions?\n",
    "\n",
    "There are many metrics to evaluate a model and two ways we can get estimates \n",
    "- 'in-sample' evaluating on our training data \n",
    "- 'out of sample' evaluating on our testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in sample accuracy \n",
    "metrics.accuracy_score(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on testing dataset\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of of sample accuracy \n",
    "# Let's check the overall accuracy for the test set \n",
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The in-sample estimate always tends to be higher accuracy - which is why we need to evaluate our model on data it has not seen before to get a true estimate of real life performance! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix \n",
    "\n",
    "For classification models we can use a tool called a **confusion matrix** to see how the model performed on classifying non-conversions compared to conversions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "# imput is the actual conversions vs the predicted conversions for each lead in the test set\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we are interested in how many leads predicted as converters were actually converters and how many predicted as non-converters were actually non converters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more things we can calculate from our confusion matrix\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "print(\"True positive\", TP)\n",
    "print(\"True negative\", TN)\n",
    "print(\"False Positives\", FP)\n",
    "print(\"False Negatives\", FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the proportions of each:\n",
    "\n",
    "- **Sensitivity** (also called the true positive rate, the recall) measures the proportion of actual positives that are correctly identified as such (e.g., the percentage of sick people who are correctly identified as having the condition).\n",
    "\n",
    "- **Specificity** (also called the true negative rate) measures the proportion of actual negatives that are correctly identified as such (e.g., the percentage of healthy people who are correctly identified as not having the condition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "se = TP / float(TP+FN)\n",
    "# Let us calculate specificity\n",
    "sp = TN / float(TN+FP)\n",
    "\n",
    "# Out of all those who were converters - what proportion did our model get right?\n",
    "print(\"Sensitivity\", se)\n",
    "# Out of all those who were non-converters - what proportion did our model get right?\n",
    "print(\"Specificity\", sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Interpreting Results & Lift\n",
    "\n",
    "The great thing about logistic regression is it gives us the predicted probabilities of that observation falling into that class (in our case conversion = 0 or conversion = 1). \n",
    "\n",
    "We can use this to rank our leads into deciles of the 'hottest' and compare the number of actual conversions in each decile.\n",
    "\n",
    "Then we can see how this compares to the existing method - or no method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting predicted probabilities and combining into a dataframe\n",
    "probs = pd.DataFrame(model.predict_proba(X_test), columns = ['prob_nc', 'prob_c'])\n",
    "\n",
    "# joining actual outcomes\n",
    "probs['actual'] = y_test.reset_index(drop=True)\n",
    "\n",
    "probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut data into decilies \n",
    "# i.e. putting the leads into buckets of top 10%, 20%, ... based on how likely they are to convert\n",
    "d = np.linspace(0.1,1,10).round(1)\n",
    "probs['deciles'] = pd.qcut(probs.prob_c, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare actual conversion in each decile\n",
    "# pandas groupby is a useful function for \n",
    "lift = probs.groupby(probs.deciles)['actual'].agg([\"sum\", \"count\"]).reset_index()\n",
    "\n",
    "# existing conversion rate in test data\n",
    "x = sum(lift['sum'])/sum(lift['count'])\n",
    "\n",
    "# calculate conversion probs\n",
    "lift['prob_con'] = lift['sum']/lift['count']\n",
    "\n",
    "# get cumulative counts and probabilities \n",
    "lift['sum_c'] = lift['sum'].iloc[::-1].cumsum()\n",
    "lift['prop_c'] = lift['sum_c']/731\n",
    "\n",
    "# old model - 40% conversion by random selection\n",
    "lift['old'] = lift['count']*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with our metrics \n",
    "lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waterfall Plot\n",
    "\n",
    "This plot shows us for each decile (ordered 'hottest' to 'not hot' leads) how many conversions we would expect to get by contacting leads in each decile compared to when we just pick leads at random that have a 38% conversion rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall analysis plot \n",
    "ax = plt.gca()\n",
    "\n",
    "ax.bar(lift.index, lift['sum'].iloc[::-1])\n",
    "ax.plot(lift.index, lift['old'].iloc[::-1], color = 'red')\n",
    "plt.xticks(lift.index, labels=lift.index+1)\n",
    "plt.title(\"Waterfall Analysis\")\n",
    "plt.xlabel(\"Deciles\")\n",
    "plt.ylabel(\"Conversions\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model puts our more likely converters in the top deciles. This means that the sales team has a way of prioritising leads\n",
    "1. Top 10% of leads are 98% likely to convert so they should always be at the top of the queue \n",
    "2. Middle % of leads might still convert but not a priority \n",
    "3. Bottom 30% of leads are very unlikely to convert - don't waste time and resource here \n",
    "\n",
    "*Next idea - can you work out those in the top decile who might convert on without even needing a sales call? - AB testing* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift plot\n",
    "\n",
    "Here we compare the cumulative gains in converted customer we get from our model compared to what we get by calling leads randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift plot\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(lift.index, lift['prop_c'].iloc[::-1]*100, marker='o')\n",
    "ax.plot(lift.index, d*100, color = 'red', marker='o')\n",
    "plt.xticks(lift.index, labels=d*100)\n",
    "plt.title(\"Lift Chart\")\n",
    "plt.xlabel(\"% of Leads\")\n",
    "plt.ylabel(\"% of Conversions\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows us that by contacting just the top 10% of leads we actually capture 24% of all conversions. \n",
    "\n",
    "This is compared to having no model where we will only get 10% of all conversions for every 10% of leads we contact. \n",
    "\n",
    "We only need to contact the top 70% leads from our model to capture 95% of all conversions. \n",
    "\n",
    "This model shows we can increase the leads generated but do not have to increase the sales team to contact all customers to grow the customer base!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 10: Next steps\n",
    "\n",
    "You could try improve model accuracy by:\n",
    "- Try a different model\n",
    "- Transform variables\n",
    "- Variable selection\n",
    "- Tune hyperparameters \n",
    "- Adding new data \n",
    "\n",
    "Model building is an iterative process until you reach the level of accuracy required "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
